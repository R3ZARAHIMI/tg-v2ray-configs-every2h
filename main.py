import re
import asyncio
import base64
import json
import yaml
import os
import datetime
import ipaddress
import socket
import geoip2.database
from urllib.parse import urlparse, parse_qs, unquote, urlunparse
from pyrogram import Client, enums
from pyrogram.errors import FloodWait
from typing import Optional, Dict, Any, Set, List

# =================================================================================
# Settings and Constants
# =================================================================================

API_ID = int(os.environ.get("API_ID"))
API_HASH = os.environ.get("API_HASH")
SESSION_STRING = os.environ.get("SESSION_STRING")
CHANNELS_STR = os.environ.get('CHANNELS_LIST')
GROUPS_STR = os.environ.get('GROUPS_LIST')
CHANNEL_SEARCH_LIMIT = int(os.environ.get('CHANNEL_SEARCH_LIMIT', 5))
GROUP_SEARCH_LIMIT = int(os.environ.get('GROUP_SEARCH_LIMIT', 100))

OUTPUT_YAML_PRO = "Config-jo.yaml"
OUTPUT_TXT = "Config_jo.txt"
OUTPUT_JSON_CONFIG_JO = "Config_jo.json"
OUTPUT_ORIGINAL_CONFIGS = "Original-Configs.txt"
OUTPUT_NO_CF = "Config_no_cf.txt"

WEEKLY_FILE = "conf-week.txt"
HISTORY_FILE = "conf-week-history.json"
GEOIP_DATABASE_PATH = 'dbip-country-lite.mmdb'

NO_CF_HISTORY_FILE = "no_cf_history.json"
BLOCKED_IPS_FILE = "blocked_ips.txt"

CHANNEL_MAX_INACTIVE_DAYS = 4

V2RAY_PATTERNS = [
    re.compile(r'(vless:\/\/[^\s\'\"<>`]+)'), re.compile(r'(vmess:\/\/[^\s\'\"<>`]+)'),
    re.compile(r'(trojan:\/\/[^\s\'\"<>`]+)'), re.compile(r'(ss:\/\/[^\s\'\"<>`]+)'),
    re.compile(r"(hy2://[^\s'\"<>`]+)"), re.compile(r"(hysteria2://[^\s'\"<>`]+)"),
    re.compile(r"(tuic://[^\s'\"<>`]+)")
]
BASE64_PATTERN = re.compile(r"([A-Za-z0-9+/=]{50,})", re.MULTILINE)

COUNTRY_FLAGS = {
    'AD': 'ðŸ‡¦ðŸ‡©', 'AE': 'ðŸ‡¦ðŸ‡ª', 'AF': 'ðŸ‡¦ðŸ‡«', 'AG': 'ðŸ‡¦ðŸ‡¬', 'AI': 'ðŸ‡¦ðŸ‡®', 'AL': 'ðŸ‡¦ðŸ‡±', 'AM': 'ðŸ‡¦ðŸ‡²', 'AO': 'ðŸ‡¦ðŸ‡´', 'AQ': 'ðŸ‡¦ðŸ‡¶', 'AR': 'ðŸ‡¦ðŸ‡·', 'AS': 'ðŸ‡¦ðŸ‡¸', 'AT': 'ðŸ‡¦ðŸ‡¹', 'AU': 'ðŸ‡¦ðŸ‡º', 'AW': 'ðŸ‡¦ðŸ‡¼', 'AX': 'ðŸ‡¦ðŸ‡½', 'AZ': 'ðŸ‡¦ðŸ‡¿', 'BA': 'ðŸ‡§ðŸ‡¦', 'BB': 'ðŸ‡§ðŸ‡§', 'BD': 'ðŸ‡§ðŸ‡©', 'BE': 'ðŸ‡§ðŸ‡ª', 'BF': 'ðŸ‡§ðŸ‡«', 'BG': 'ðŸ‡§ðŸ‡¬', 'BH': 'ðŸ‡§ðŸ‡­', 'BI': 'ðŸ‡§ðŸ‡®', 'BJ': 'ðŸ‡§ðŸ‡¯', 'BL': 'ðŸ‡§ðŸ‡±', 'BM': 'ðŸ‡§ðŸ‡²', 'BN': 'ðŸ‡§ðŸ‡³', 'BO': 'ðŸ‡§ðŸ‡´', 'BR': 'ðŸ‡§ðŸ‡·', 'BS': 'ðŸ‡§ðŸ‡¸', 'BT': 'ðŸ‡§ðŸ‡¹', 'BW': 'ðŸ‡§ðŸ‡¼', 'BY': 'ðŸ‡§ðŸ‡¾', 'BZ': 'ðŸ‡§ðŸ‡¿', 'CA': 'ðŸ‡¨ðŸ‡¦', 'CC': 'ðŸ‡¨ðŸ‡¨', 'CD': 'ðŸ‡¨ðŸ‡©', 'CF': 'ðŸ‡¨ðŸ‡«', 'CG': 'ðŸ‡¨ðŸ‡¬', 'CH': 'ðŸ‡¨ðŸ‡­', 'CI': 'ðŸ‡¨ðŸ‡®', 'CK': 'ðŸ‡¨ðŸ‡°', 'CL': 'ðŸ‡¨ðŸ‡±', 'CM': 'ðŸ‡¨ðŸ‡²', 'CN': 'ðŸ‡¨ðŸ‡³', 'CO': 'ðŸ‡¨ðŸ‡´', 'CR': 'ðŸ‡¨ðŸ‡·', 'CU': 'ðŸ‡¨ðŸ‡º', 'CV': 'ðŸ‡¨ðŸ‡»', 'CW': 'ðŸ‡¨ðŸ‡¼', 'CX': 'ðŸ‡¨ðŸ‡½', 'CY': 'ðŸ‡¨ðŸ‡¾', 'CZ': 'ðŸ‡¨ðŸ‡¿', 'DE': 'ðŸ‡©ðŸ‡ª', 'DJ': 'ðŸ‡©ðŸ‡¯', 'DK': 'ðŸ‡©ðŸ‡°', 'DM': 'ðŸ‡©ðŸ‡²', 'DO': 'ðŸ‡©ðŸ‡´', 'DZ': 'ðŸ‡©ðŸ‡¿', 'EC': 'ðŸ‡ªðŸ‡¨', 'EE': 'ðŸ‡ªðŸ‡ª', 'EG': 'ðŸ‡ªðŸ‡¬', 'EH': 'ðŸ‡ªðŸ‡­', 'ER': 'ðŸ‡ªðŸ‡·', 'ES': 'ðŸ‡ªðŸ‡¸', 'ET': 'ðŸ‡ªðŸ‡¹', 'FI': 'ðŸ‡«ðŸ‡®', 'FJ': 'ðŸ‡«ðŸ‡¯', 'FK': 'ðŸ‡«ðŸ‡°', 'FM': 'ðŸ‡«ðŸ‡²', 'FO': 'ðŸ‡«ðŸ‡´', 'FR': 'ðŸ‡«ðŸ‡·', 'GA': 'ðŸ‡¬ðŸ‡¦', 'GB': 'ðŸ‡¬ðŸ‡¬', 'GD': 'ðŸ‡¬ðŸ‡©', 'GE': 'ðŸ‡¬ðŸ‡ª', 'GF': 'ðŸ‡¬ðŸ‡«', 'GG': 'ðŸ‡¬ðŸ‡¬', 'GH': 'ðŸ‡¬ðŸ‡­', 'GI': 'ðŸ‡¬ðŸ‡®', 'GL': 'ðŸ‡¬ðŸ‡±', 'GM': 'ðŸ‡¬ðŸ‡²', 'GN': 'ðŸ‡¬ðŸ‡³', 'GP': 'ðŸ‡¬ðŸ‡µ', 'GQ': 'ðŸ‡¬ðŸ‡¶', 'GR': 'ðŸ‡¬ðŸ‡·', 'GT': 'ðŸ‡¬ðŸ‡¹', 'GU': 'ðŸ‡¬ðŸ‡º', 'GW': 'ðŸ‡¬ðŸ‡¼', 'GY': 'ðŸ‡¬ðŸ‡¾', 'HK': 'ðŸ‡­ðŸ‡°', 'HN': 'ðŸ‡­ðŸ‡³', 'HR': 'ðŸ‡­ðŸ‡·', 'HT': 'ðŸ‡­ðŸ‡¹', 'HU': 'ðŸ‡­ðŸ‡º', 'ID': 'ðŸ‡®ðŸ‡©', 'IE': 'ðŸ‡®ðŸ‡ª', 'IL': 'ðŸ‡®ðŸ‡±', 'IM': 'ðŸ‡®ðŸ‡²', 'IN': 'ðŸ‡®ðŸ‡³', 'IO': 'ðŸ‡®ðŸ‡´', 'IQ': 'ðŸ‡®ðŸ‡¶', 'IR': 'ðŸ‡®ðŸ‡·', 'IS': 'ðŸ‡®ðŸ‡¸', 'IT': 'ðŸ‡®ðŸ‡¹', 'JE': 'ðŸ‡¯ðŸ‡ª', 'JM': 'ðŸ‡¯ðŸ‡²', 'JO': 'ðŸ‡¯ðŸ‡´', 'JP': 'ðŸ‡¯ðŸ‡µ', 'KE': 'ðŸ‡°ðŸ‡ª', 'KG': 'ðŸ‡°ðŸ‡¬', 'KH': 'ðŸ‡°ðŸ‡­', 'KI': 'ðŸ‡°ðŸ‡®', 'KM': 'ðŸ‡°ðŸ‡²', 'KN': 'ðŸ‡°ðŸ‡³', 'KP': 'ðŸ‡°ðŸ‡µ', 'KR': 'ðŸ‡°ðŸ‡·', 'KW': 'ðŸ‡°ðŸ‡¼', 'KY': 'ðŸ‡°ðŸ‡¾', 'KZ': 'ðŸ‡°ðŸ‡¿', 'LA': 'ðŸ‡±ðŸ‡¦', 'LB': 'ðŸ‡±ðŸ‡§', 'LC': 'ðŸ‡±ðŸ‡¨', 'LI': 'ðŸ‡±ðŸ‡®', 'LK': 'ðŸ‡±ðŸ‡°', 'LR': 'ðŸ‡±ðŸ‡·', 'LS': 'ðŸ‡±ðŸ‡¸', 'LT': 'ðŸ‡±ðŸ‡¹', 'LU': 'ðŸ‡±ðŸ‡º', 'LV': 'ðŸ‡±ðŸ‡»', 'LY': 'ðŸ‡±ðŸ‡¾', 'MA': 'ðŸ‡²ðŸ‡¦', 'MC': 'ðŸ‡²ðŸ‡¨', 'MD': 'ðŸ‡²ðŸ‡©', 'ME': 'ðŸ‡²ðŸ‡ª', 'MF': 'ðŸ‡²ðŸ‡«', 'MG': 'ðŸ‡²ðŸ‡¬', 'MH': 'ðŸ‡²ðŸ‡­', 'MK': 'ðŸ‡²ðŸ‡°', 'ML': 'ðŸ‡²ðŸ‡±', 'MM': 'ðŸ‡²ðŸ‡²', 'MN': 'ðŸ‡²ðŸ‡³', 'MO': 'ðŸ‡²ðŸ‡´', 'MP': 'ðŸ‡²ðŸ‡µ', 'MQ': 'ðŸ‡²ðŸ‡¶', 'MR': 'ðŸ‡²ðŸ‡·', 'MS': 'ðŸ‡²ðŸ‡¸', 'MT': 'ðŸ‡²ðŸ‡¹', 'MU': 'ðŸ‡²ðŸ‡º', 'MV': 'ðŸ‡²ðŸ‡»', 'MW': 'ðŸ‡²ðŸ‡¼', 'MX': 'ðŸ‡²ðŸ‡½', 'MY': 'ðŸ‡²ðŸ‡¾', 'MZ': 'ðŸ‡²ðŸ‡¿', 'NA': 'ðŸ‡³ðŸ‡¦', 'NC': 'ðŸ‡³ðŸ‡¨', 'NE': 'ðŸ‡³ðŸ‡ª', 'NF': 'ðŸ‡³ðŸ‡«', 'NG': 'ðŸ‡³ðŸ‡¬', 'NI': 'ðŸ‡³ðŸ‡®', 'NL': 'ðŸ‡³ðŸ‡±', 'NO': 'ðŸ‡³ðŸ‡´', 'NP': 'ðŸ‡³ðŸ‡µ', 'NR': 'ðŸ‡³ðŸ‡·', 'NU': 'ðŸ‡³ðŸ‡º', 'NZ': 'ðŸ‡³ðŸ‡¿', 'OM': 'ðŸ‡´ðŸ‡²', 'PA': 'ðŸ‡µðŸ‡¦', 'PE': 'ðŸ‡µðŸ‡ª', 'PF': 'ðŸ‡µðŸ‡«', 'PG': 'ðŸ‡µðŸ‡¬', 'PH': 'ðŸ‡µðŸ‡­', 'PK': 'ðŸ‡µðŸ‡°', 'PL': 'ðŸ‡µðŸ‡±', 'PM': 'ðŸ‡µðŸ‡²', 'PN': 'ðŸ‡µðŸ‡³', 'PR': 'ðŸ‡µðŸ‡·', 'PS': 'ðŸ‡µðŸ‡¸', 'PT': 'ðŸ‡µðŸ‡¹', 'PW': 'ðŸ‡µðŸ‡¼', 'PY': 'ðŸ‡µðŸ‡¾', 'QA': 'ðŸ‡¶ðŸ‡¦', 'RE': 'ðŸ‡·ðŸ‡ª', 'RO': 'ðŸ‡·ðŸ‡´', 'RS': 'ðŸ‡·ðŸ‡¸', 'RU': 'ðŸ‡·ðŸ‡º', 'RW': 'ðŸ‡·ðŸ‡¼', 'SA': 'ðŸ‡¸ðŸ‡¦', 'SB': 'ðŸ‡¸ðŸ‡§', 'SC': 'ðŸ‡¸ðŸ‡¨', 'SD': 'ðŸ‡¸ðŸ‡©', 'SE': 'ðŸ‡¸ðŸ‡ª', 'SG': 'ðŸ‡¸ðŸ‡¬', 'SH': 'ðŸ‡¸ðŸ‡­', 'SI': 'ðŸ‡¸ðŸ‡®', 'SK': 'ðŸ‡¸ðŸ‡°', 'SL': 'ðŸ‡¸ðŸ‡±', 'SM': 'ðŸ‡¸ðŸ‡²', 'SN': 'ðŸ‡¸ðŸ‡³', 'SO': 'ðŸ‡¸ðŸ‡´', 'SR': 'ðŸ‡¸ðŸ‡·', 'SS': 'ðŸ‡¸ðŸ‡¸', 'ST': 'ðŸ‡¸ðŸ‡¹', 'SV': 'ðŸ‡¸ðŸ‡»', 'SX': 'ðŸ‡¸ðŸ‡½', 'SY': 'ðŸ‡¸ðŸ‡¾', 'SZ': 'ðŸ‡¸ðŸ‡¿', 'TC': 'ðŸ‡¹ðŸ‡¨', 'TD': 'ðŸ‡¹ðŸ‡©', 'TG': 'ðŸ‡¹ðŸ‡¬', 'TH': 'ðŸ‡¹ðŸ‡­', 'TJ': 'ðŸ‡¹ðŸ‡¯', 'TK': 'ðŸ‡¹ðŸ‡°', 'TL': 'ðŸ‡¹ðŸ‡±', 'TM': 'ðŸ‡¹ðŸ‡²', 'TN': 'ðŸ‡¹ðŸ‡³', 'TO': 'ðŸ‡¹ðŸ‡´', 'TR': 'ðŸ‡¹ðŸ‡·', 'TT': 'ðŸ‡¹ðŸ‡¹', 'TV': 'ðŸ‡¹ðŸ‡»', 'TW': 'ðŸ‡¹ðŸ‡¼', 'TZ': 'ðŸ‡¹ðŸ‡¿', 'UA': 'ðŸ‡ºðŸ‡¦', 'UG': 'ðŸ‡ºðŸ‡¬', 'US': 'ðŸ‡ºðŸ‡¸', 'UY': 'ðŸ‡ºðŸ‡¾', 'UZ': 'ðŸ‡ºðŸ‡¿', 'VA': 'ðŸ‡»ðŸ‡¦', 'VC': 'ðŸ‡»ðŸ‡¨', 'VE': 'ðŸ‡»ðŸ‡ª', 'VG': 'ðŸ‡»ðŸ‡¬', 'VI': 'ðŸ‡»ðŸ‡®', 'VN': 'ðŸ‡»ðŸ‡³', 'VU': 'ðŸ‡»ðŸ‡º', 'WF': 'ðŸ‡¼ðŸ‡«', 'WS': 'ðŸ‡¼ðŸ‡¸', 'YE': 'ðŸ‡¾ðŸ‡ª', 'YT': 'ðŸ‡¾ðŸ‡¹', 'ZA': 'ðŸ‡¿ðŸ‡¦', 'ZM': 'ðŸ‡¿ðŸ‡²', 'ZW': 'ðŸ‡¿ðŸ‡¼'
}

GEOIP_READER = None
BLOCKED_NETWORKS = []

def load_ip_data():
    global GEOIP_READER
    try:
        GEOIP_READER = geoip2.database.Reader(GEOIP_DATABASE_PATH)
    except Exception:
        pass

def load_blocked_ips():
    global BLOCKED_NETWORKS
    if os.path.exists(BLOCKED_IPS_FILE):
        try:
            with open(BLOCKED_IPS_FILE, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        try:
                            BLOCKED_NETWORKS.append(ipaddress.ip_network(line, strict=False))
                        except ValueError:
                            pass
        except Exception:
            pass

def is_clean_ip(host: str) -> bool:
    try:
        ip = ipaddress.ip_address(host)
        for network in BLOCKED_NETWORKS:
            if ip in network:
                return False 
        return True 
    except ValueError:
        return False 

def process_lists():
    channels = [ch.strip() for ch in CHANNELS_STR.split(',')] if CHANNELS_STR else []
    groups = []
    if GROUPS_STR:
        try:
            groups = [int(g.strip()) for g in GROUPS_STR.split(',')]
        except ValueError: pass
    return channels, groups

CHANNELS, GROUPS = process_lists()

class V2RayExtractor:
    def __init__(self):
        self.raw_configs: Set[str] = set()
        self.client = Client("my_account", api_id=API_ID, api_hash=API_HASH, session_string=SESSION_STRING)

    def get_country_iso_code(self, hostname: str) -> str:
        if not hostname or not GEOIP_READER: return "N/A"
        try:
            ip_address = hostname
            try: socket.inet_aton(hostname)
            except: ip_address = socket.gethostbyname(hostname)
            response = GEOIP_READER.country(ip_address)
            return response.country.iso_code or "N/A"
        except: return "N/A"

    def _is_valid_shadowsocks(self, ss_url: str) -> bool:
        try:
            if '@' in ss_url:
                parts = ss_url.split('@')
                if len(parts) >= 2: return True
            return False
        except: return False

    def _correct_config_type(self, config_url: str) -> str:
        if config_url.startswith('ss://') and 'v=2' in config_url: return config_url.replace('ss://', 'vmess://', 1)
        return config_url

    def _validate_config_type(self, config_url: str) -> bool:
        try:
            if config_url.startswith('vless://'): return True
            elif config_url.startswith('vmess://'):
                decoded_str = base64.b64decode(config_url[8:] + '=' * 4).decode('utf-8')
                config = json.loads(decoded_str)
                return bool(config.get('add') and config.get('id'))
            elif config_url.startswith('trojan://'): return True
            elif config_url.startswith('ss://'): return self._is_valid_shadowsocks(config_url)
            return True
        except: return False

    def parse_config_for_clash(self, config_url: str) -> Optional[Dict[str, Any]]:
        parsers = {'vmess://': self.parse_vmess, 'vless://': self.parse_vless, 'trojan://': self.parse_trojan, 'ss://': self.parse_shadowsocks, 'hysteria2://': self.parse_hysteria2, 'hy2://': self.parse_hysteria2, 'tuic://': self.parse_tuic}
        for prefix, parser in parsers.items():
            if config_url.startswith(prefix):
                try: return parser(config_url)
                except: return None
        return None

    def parse_vmess(self, vmess_url: str) -> Optional[Dict[str, Any]]:
        decoded_str = base64.b64decode(vmess_url[8:] + '=' * 4).decode('utf-8')
        c = json.loads(decoded_str)
        ws_opts = None
        if c.get('net') == 'ws':
            ws_opts = {'path': c.get('path', '/'), 'headers': {'Host': c.get('host', '')}}
        return {'name': c.get('ps', ''), 'type': 'vmess', 'server': c.get('add'), 'port': int(c.get('port', 443)), 'uuid': c.get('id'), 'alterId': int(c.get('aid', 0)), 'cipher': c.get('scy', 'auto'), 'tls': c.get('tls')=='tls', 'network': c.get('net', 'tcp'), 'udp': True, 'ws-opts': ws_opts, 'servername': c.get('sni', c.get('host'))}

    def parse_vless(self, vless_url: str) -> Optional[Dict[str, Any]]:
        p, q = urlparse(vless_url), parse_qs(urlparse(vless_url).query)
        ws_opts, reality_opts = None, None
        if q.get('type', [''])[0] == 'ws':
            ws_opts = {'path': q.get('path', ['/'])[0], 'headers': {'Host': q.get('host', [''])[0]}}
        if q.get('security', [''])[0] == 'reality':
            reality_opts = {'public-key': q.get('pbk', [''])[0], 'short-id': q.get('sid', [''])[0]}
        return {'name': unquote(p.fragment or ''), 'type': 'vless', 'server': p.hostname, 'port': p.port or 443, 'uuid': p.username, 'udp': True, 'tls': q.get('security', [''])[0] in ['tls', 'reality'], 'network': q.get('type', ['tcp'])[0], 'servername': q.get('sni', [None])[0], 'ws-opts': ws_opts, 'reality-opts': reality_opts}

    def parse_trojan(self, trojan_url: str) -> Optional[Dict[str, Any]]:
        p, q = urlparse(trojan_url), parse_qs(urlparse(trojan_url).query)
        return {'name': unquote(p.fragment or ''), 'type': 'trojan', 'server': p.hostname, 'port': p.port or 443, 'password': p.username, 'udp': True, 'sni': q.get('sni', [None])[0]}

    def parse_shadowsocks(self, ss_url: str) -> Optional[Dict[str, Any]]:
        try:
            content = ss_url[5:]
            name = ''
            if '#' in content:
                content, name_encoded = content.split('#', 1)
                name = unquote(name_encoded)
            if '@' not in content: return None
            userinfo_b64, server_part = content.rsplit('@', 1)
            if ':' in server_part:
                server_host, server_port_str = server_part.rsplit(':', 1)
                port = int(server_port_str)
            else: return None
            userinfo_b64_padded = userinfo_b64 + '=' * (-len(userinfo_b64) % 4)
            try:
                userinfo_bytes = base64.b64decode(userinfo_b64_padded, validate=False)
                userinfo_str = userinfo_bytes.decode('utf-8')
            except:
                userinfo_bytes = base64.urlsafe_b64decode(userinfo_b64_padded)
                userinfo_str = userinfo_bytes.decode('utf-8')
            if ':' in userinfo_str:
                cipher, password = userinfo_str.split(':', 1)
                return {'name': name, 'type': 'ss', 'server': server_host, 'port': port, 'cipher': cipher, 'password': password, 'udp': True}
            return None
        except: return None

    def parse_hysteria2(self, hy2_url: str) -> Optional[Dict[str, Any]]:
        p, q = urlparse(hy2_url), parse_qs(urlparse(hy2_url).query)
        return {'name': unquote(p.fragment or ''), 'type': 'hysteria2', 'server': p.hostname, 'port': p.port or 443, 'auth': p.username, 'up': q.get('up', [''])[0], 'down': q.get('down', [''])[0], 'sni': q.get('sni', [p.hostname])[0], 'skip-cert-verify': q.get('insecure', ['0'])[0]=='1'}

    def parse_tuic(self, tuic_url: str) -> Optional[Dict[str, Any]]:
        p, q = urlparse(tuic_url), parse_qs(urlparse(tuic_url).query)
        return {'name': unquote(p.fragment or ''), 'type': 'tuic', 'server': p.hostname, 'port': p.port or 443, 'uuid': p.username, 'password': q.get('password', [''])[0], 'udp': True, 'sni': q.get('sni', [p.hostname])[0], 'skip-cert-verify': q.get('allow_insecure', ['0'])[0]=='1'}

    def generate_sip002_link(self, proxy: Dict[str, Any]) -> str:
        try:
            userinfo = f"{proxy['cipher']}:{proxy['password']}"
            userinfo_b64 = base64.urlsafe_b64encode(userinfo.encode('utf-8')).decode('utf-8').rstrip('=')
            name = proxy.get('name', 'Shadowsocks')
            return f"ss://{userinfo_b64}@{proxy['server']}:{proxy['port']}#{name}"
        except: return None

    def convert_to_singbox_outbound(self, proxy: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        if not proxy: return None
        t = proxy['type']
        out = {'type': t if t!='ss' else 'shadowsocks', 'tag': proxy['name'], 'server': proxy['server'], 'server_port': proxy['port']}
        if t=='vmess': out.update({'uuid': proxy['uuid'], 'alter_id': proxy['alterId'], 'security': proxy['cipher'], 'tls': {'enabled': True, 'server_name': proxy['servername']} if proxy.get('tls') else None})
        if t=='vless': out.update({'uuid': proxy['uuid'], 'flow': proxy.get('flow',''), 'tls': {'enabled': True, 'server_name': proxy['servername'], 'reality': {'enabled': True, 'public_key': proxy.get('reality-opts',{}).get('public-key'), 'short_id': proxy.get('reality-opts',{}).get('short-id')} if proxy.get('reality-opts') else None} if proxy.get('tls') else None})
        if t=='trojan': out.update({'password': proxy['password'], 'tls': {'enabled': True, 'server_name': proxy.get('sni')}})
        if t=='ss': out.update({'method': proxy['cipher'], 'password': proxy['password']})
        if t in ['hysteria2','tuic']: out.update({'password': proxy.get('auth') or proxy.get('password'), 'tls': {'enabled': True, 'server_name': proxy['sni'], 'insecure': proxy.get('skip-cert-verify')}})
        if proxy.get('ws-opts'): out['transport'] = {'type': 'ws', 'path': proxy['ws-opts']['path'], 'headers': proxy['ws-opts']['headers']}
        return out

    def extract_configs_from_text(self, text: str) -> Set[str]:
        found = set()
        for pattern in V2RAY_PATTERNS:
            found.update(pattern.findall(text))
        clean_configs = set()
        for url in found:
            url = url.strip()
            if not url.startswith('vmess://') and '#' in url:
                url = url.split('#')[0]
            if corrected := self._correct_config_type(url):
                if self._validate_config_type(corrected):
                    clean_configs.add(corrected)
        return clean_configs

    async def find_raw_configs_from_chat(self, chat_id: int, limit: int, retries: int = 3):
        local_configs = set()
        try:
            is_active = False
            async for last_msg in self.client.get_chat_history(chat_id, limit=1):
                if last_msg.date > (datetime.datetime.now() - datetime.timedelta(days=CHANNEL_MAX_INACTIVE_DAYS)):
                    is_active = True
                break 

            if not is_active: return

            async for message in self.client.get_chat_history(chat_id, limit=limit):
                text_to_check = message.text or message.caption or ""
                texts_to_scan = [text_to_check]
                if message.entities:
                    valid_types = [enums.MessageEntityType.CODE, enums.MessageEntityType.PRE]
                    for attr in ['BLOCKQUOTE', 'EXPANDABLE_BLOCKQUOTE']:
                        if hasattr(enums.MessageEntityType, attr): valid_types.append(getattr(enums.MessageEntityType, attr))
                    for entity in message.entities:
                        if entity.type in valid_types:
                            texts_to_scan.append(text_to_check[entity.offset : entity.offset + entity.length].replace('\n', '').replace(' ', ''))
                for b64_str in BASE64_PATTERN.findall(text_to_check):
                    try: texts_to_scan.append(base64.b64decode(b64_str + '=' * 4).decode('utf-8', errors='ignore'))
                    except: continue
                for text in texts_to_scan:
                    if text: local_configs.update(self.extract_configs_from_text(text))
            self.raw_configs.update(local_configs)
        except FloodWait as e:
            if retries > 0:
                await asyncio.sleep(e.value + 2)
                await self.find_raw_configs_from_chat(chat_id, limit, retries - 1)
        except Exception: pass

    def handle_weekly_file(self, new_configs: List[str]):
        now = datetime.datetime.now()
        cutoff = now - datetime.timedelta(days=7)
        history = {}
        if os.path.exists(HISTORY_FILE):
            try:
                with open(HISTORY_FILE, 'r') as f: history = json.load(f)
            except: history = {}
        new_history = {k: v for k, v in history.items() if datetime.datetime.fromisoformat(v['date']) > cutoff}
        for cfg in new_configs:
            base = cfg.split('#')[0]
            if base not in new_history: new_history[base] = {"link": cfg, "date": now.isoformat()}
        with open(HISTORY_FILE, 'w') as f: json.dump(new_history, f, indent=2)
        with open(WEEKLY_FILE, 'w', encoding='utf-8') as f: f.write("\n".join(sorted([m['link'] for m in new_history.values()])))

    def handle_no_cf_retention(self, new_configs: List[str]):
        now, cutoff = datetime.datetime.now(), datetime.datetime.now() - datetime.timedelta(hours=72)
        history = {}
        if os.path.exists(NO_CF_HISTORY_FILE):
            try:
                with open(NO_CF_HISTORY_FILE, 'r') as f: history = json.load(f)
            except: history = {}
        new_history = {k: v for k, v in history.items() if datetime.datetime.fromisoformat(v['date']) > cutoff}
        for cfg in new_configs:
            proxy = self.parse_config_for_clash(cfg)
            uid = str(proxy.get('uuid') or proxy.get('password') or proxy.get('auth')) if proxy else cfg.split('#')[0]
            if uid not in new_history: new_history[uid] = {"link": cfg, "date": now.isoformat()}
        with open(NO_CF_HISTORY_FILE, 'w') as f: json.dump(new_history, f, indent=2)
        with open(OUTPUT_NO_CF, 'w', encoding='utf-8') as f: f.write("\n".join(sorted([m['link'] for m in new_history.values()])))

    def save_files(self):
        if not self.raw_configs: return
        valid_configs = set()
        for url in self.raw_configs:
            try:
                if not url.startswith('ss://') and not urlparse(url).hostname: continue 
                if url.startswith('vless://') and parse_qs(urlparse(url).query).get('security', [''])[0] == 'none': continue 
                valid_configs.add(url)
            except: continue

        proxies_list_clash, renamed_txt_configs, clean_ip_configs = [], [], []

        for i, url in enumerate(sorted(list(valid_configs)), 1):
            if not (proxy := self.parse_config_for_clash(url)): continue
            country_code = self.get_country_iso_code(proxy.get('server'))
            proxy['name'] = f"{country_code} Config_jo-{i:02d}"
            proxies_list_clash.append(proxy)
            name_with_flag = f"{COUNTRY_FLAGS.get(country_code, 'ðŸ³ï¸')} Config_jo-{i:02d}"
            
            final_link = ""
            if proxy['type'] == 'ss':
                ss_p = proxy.copy(); ss_p['name'] = name_with_flag
                clean = self.generate_sip002_link(ss_p)
                final_link = clean if clean else f"{url.split('#')[0]}#{name_with_flag}"
            else:
                try:
                    parsed = list(urlparse(url)); parsed[5] = name_with_flag
                    final_link = urlunparse(parsed)
                except: final_link = f"{url.split('#')[0]}#{name_with_flag}"
            
            renamed_txt_configs.append(final_link)
            if proxy.get('server') and is_clean_ip(proxy.get('server')): clean_ip_configs.append(final_link)

        with open(OUTPUT_ORIGINAL_CONFIGS, 'w', encoding='utf-8') as f: f.write("\n".join(sorted(list(self.raw_configs))))
        with open(OUTPUT_TXT, 'w', encoding='utf-8') as f: f.write("\n".join(sorted(renamed_txt_configs)))
        self.handle_no_cf_retention(clean_ip_configs)
        os.makedirs('rules', exist_ok=True)
        if proxies_list_clash:
            clash_config = self.build_pro_config(proxies_list_clash)
            if clash_config:
                with open(OUTPUT_YAML_PRO, 'w', encoding='utf-8') as f:
                    yaml.dump(clash_config, f, allow_unicode=True, sort_keys=False, indent=2, width=120)
            with open(OUTPUT_JSON_CONFIG_JO, 'w', encoding='utf-8') as f:
                json.dump(self.build_sing_box_config(proxies_list_clash), f, ensure_ascii=False, indent=4)
        self.handle_weekly_file(renamed_txt_configs)

    def build_pro_config(self, proxies):
        clean_proxies, clean_names, seen_names = [], [], set()

        for p in proxies:
            if p.get('type') in ['vless', 'vmess', 'tuic'] and not p.get('uuid'): continue
            if p.get('type') == 'trojan' and not p.get('password'): continue
            if p.get('type') == 'ss' and (not p.get('cipher') or not p.get('password')): continue
            
            server = p.get('server', '')
            if not server or len(server) > 50 or re.search(r'[^\w\.\-\:]', server): continue

            # Ø§ØµÙ„Ø§Ø­ Ù‡ÙˆØ´Ù…Ù†Ø¯ SNI Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù‚Ø·Ø¹ Ø§ØªØµØ§Ù„ (Ø§ØµÙ„Ø§Ø­ Ø§ÛŒØ±Ø§Ø¯ Null Ùˆ Ø¯Ø§Ù…Ù†Ù‡ Ù‡Ø§ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±)
            sni = p.get('servername') or p.get('sni')
            if not sni or re.search(r'[^\w\.\-]', str(sni)):
                if p.get('tls') or p.get('type') in ['trojan', 'hysteria2', 'vless', 'vmess']:
                    p['servername'] = 'www.google.com'
                    p['sni'] = 'www.google.com'
                else:
                    p.pop('servername', None); p.pop('sni', None)
            
            # Ø­Ø°Ù ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø®Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ Ø³ÛŒÙ†ØªÚ©Ø³
            p_clean = {k: v for k, v in p.items() if v is not None and v != ''}
            
            name = p_clean.get('name', 'Proxy')
            counter = 1
            original_name = name
            while name in seen_names:
                name = f"{original_name}_{counter}"
                counter += 1
            p_clean['name'] = name; seen_names.add(name)
            clean_proxies.append(p_clean); clean_names.append(name)

        if not clean_proxies: return {}

        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡ DNS Ùˆ Rule-Providers (Ø§ØµÙ„Ø§Ø­ ØªÚ©Ø±Ø§Ø± DNS Ùˆ ØªØ¯Ø§Ø®Ù„ Ù¾ÙˆØ±Øª 53)
        return {
            'port': 7890, 'socks-port': 7891, 'allow-lan': True, 'mode': 'rule', 'log-level': 'info', 'ipv6': False, 'external-controller': '127.0.0.1:9090',
            'dns': {
                'enable': True, 'listen': '0.0.0.0:53', 'enhanced-mode': 'fake-ip', 'fake-ip-range': '198.18.0.1/16',
                'default-nameserver': ['1.1.1.1', '8.8.8.8'],
                'nameserver': ['https://dns.google/dns-query', 'https://cloudflare-dns.com/dns-query'],
                'fallback': ['tcp://8.8.8.8', 'tcp://1.1.1.1', 'https://dns.nextdns.io'],
                'fallback-filter': {'geoip': True, 'geoip-code': 'IR', 'ipcidr': ['240.0.0.0/4', '0.0.0.0/32', '127.0.0.0/8']}
            },
            'proxies': clean_proxies,
            'proxy-groups': [
                {'name': 'PROXY', 'type': 'select', 'proxies': ['âš¡ Auto-Select', 'DIRECT', *clean_names]},
                {'name': 'âš¡ Auto-Select', 'type': 'url-test', 'proxies': clean_names, 'url': 'http://www.gstatic.com/generate_204', 'interval': 300},
                {'name': 'ðŸ‡®ðŸ‡· Iran', 'type': 'select', 'proxies': ['DIRECT', 'PROXY']},
                {'name': 'ðŸ›‘ Block-Ads', 'type': 'select', 'proxies': ['REJECT', 'DIRECT']}
            ],
            'rule-providers': {
                'iran_domains': {'type': 'http', 'behavior': 'domain', 'url': "https://raw.githubusercontent.com/bootmortis/iran-clash-rules/main/iran-domains.txt", 'path': './rules/iran_domains.txt', 'interval': 86400},
                'blocked_domains': {'type': 'http', 'behavior': 'domain', 'url': "https://raw.githubusercontent.com/bootmortis/iran-clash-rules/main/blocked-domains.txt", 'path': './rules/blocked_domains.txt', 'interval': 86400},
                'ad_domains': {'type': 'http', 'behavior': 'domain', 'url': "https://raw.githubusercontent.com/bootmortis/iran-clash-rules/main/ad-domains.txt", 'path': './rules/ad_domains.txt', 'interval': 86400}
            },
            'rules': ['RULE-SET,ad_domains,ðŸ›‘ Block-Ads', 'RULE-SET,blocked_domains,PROXY', 'RULE-SET,iran_domains,ðŸ‡®ðŸ‡· Iran', 'GEOIP,IR,ðŸ‡®ðŸ‡· Iran', 'MATCH,PROXY']
        }

    def build_sing_box_config(self, proxies_clash: List[Dict[str, Any]]) -> Dict[str, Any]:
        outbounds = [p for p in (self.convert_to_singbox_outbound(proxy) for proxy in proxies_clash) if p]
        proxy_tags = [p['tag'] for p in outbounds]
        return {"log": {"level": "warn", "timestamp": True}, "dns": {"servers": [{"tag": "dns_proxy", "address": "https://dns.google/dns-query", "detour": "PROXY"}, {"tag": "dns_direct", "address": "1.1.1.1"}], "rules": [{"outbound": "PROXY", "server": "dns_proxy"}, {"rule_set": ["geosite-ir", "geoip-ir"], "server": "dns_direct"}, {"domain_suffix": ".ir", "server": "dns_direct"}], "final": "dns_direct", "strategy": "ipv4_only"}, "inbounds": [{"type": "mixed", "listen": "0.0.0.0", "listen_port": 2080, "sniff": True}], "outbounds": [{"type": "direct", "tag": "direct"}, {"type": "block", "tag": "block"}, {"type": "dns", "tag": "dns-out"}, *outbounds, {"type": "selector", "tag": "PROXY", "outbounds": ["auto", *proxy_tags], "default": "auto"}, {"type": "urltest", "tag": "auto", "outbounds": proxy_tags, "url": "http://www.gstatic.com/generate_204", "interval": "5m"}], "route": {"rule_set": [{"tag": "geosite-ir", "type": "remote", "format": "binary", "url": "https://cdn.jsdelivr.net/gh/Chocolate4U/Iran-sing-box-rules@rule-set/geosite-ir.srs", "download_detour": "direct"}, {"tag": "geoip-ir", "type": "remote", "format": "binary", "url": "https://cdn.jsdelivr.net/gh/Chocolate4U/Iran-sing-box-rules@rule-set/geoip-ir.srs", "download_detour": "direct"}], "rules": [{"protocol": "dns", "outbound": "dns-out"}, {"rule_set": ["geosite-ir", "geoip-ir"], "outbound": "direct"}, {"ip_is_private": True, "outbound": "direct"}], "final": "PROXY"}}

async def main():
    load_ip_data(); load_blocked_ips()
    extractor = V2RayExtractor()
    async with extractor.client:
        async for d in extractor.client.get_dialogs(): pass
        tasks = [extractor.find_raw_configs_from_chat(channel, CHANNEL_SEARCH_LIMIT) for channel in CHANNELS]
        tasks.extend(extractor.find_raw_configs_from_chat(group, GROUP_SEARCH_LIMIT) for group in GROUPS)
        if tasks: await asyncio.gather(*tasks)
    extractor.save_files()

if __name__ == "__main__":
    if all([API_ID, API_HASH, SESSION_STRING]): asyncio.run(main())
